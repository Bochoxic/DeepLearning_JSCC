{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a7vebf0-S-QV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIMJvWux-BQ0",
        "outputId": "9fa227ad-d4f9-4ceb-8dc6-bd5c0e17c5c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 64   # patch size (Height and Width)\n",
        "enc_chs = 5 * 4*2    # compression_ratio = 5 * 1/12\n",
        "stages_count = 5\n",
        "dec_chs = enc_chs // stages_count\n",
        "SNR = 13\n",
        "\n",
        "epochs = 500\n",
        "batch_size = int(32 * (32/ps)**2)\n",
        "loss_func = torch.nn.MSELoss()  # PyTorch Mean Squared Error Loss\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/imagenetv2-matched-frequency-format-val\"\n",
        "\n",
        "train_count = int(50000 * (32/ps)**2)   # number of patches in trainset\n",
        "test_count = int(10000 * (32/ps)**2)   # number of patches in testset"
      ],
      "metadata": {
        "id": "ohAPHA6zTCuu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PowerNormParts(nn.Module):\n",
        "    def __init__(self, parts_count, cplx=False, part_last_dim=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.pc = parts_count\n",
        "        self.cplx = cplx\n",
        "        self.part_last_dim = part_last_dim\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        shape = inputs.shape\n",
        "        if self.part_last_dim:\n",
        "            inputs = inputs.reshape(shape[0], -1, shape[-1]).transpose(1, 2)\n",
        "\n",
        "        flatp = inputs.reshape(shape[0], self.pc, -1)\n",
        "        if self.cplx:\n",
        "            dsize = flatp.shape[2] // 2\n",
        "        else:\n",
        "            dsize = flatp.shape[2]\n",
        "        dsize_f = torch.tensor(dsize).float()\n",
        "\n",
        "        norm = torch.norm(flatp, dim=2, keepdim=True)\n",
        "\n",
        "        out = torch.sqrt(dsize_f) * flatp / norm\n",
        "        if self.part_last_dim:\n",
        "            out = out.reshape(shape[0], shape[-1], -1).transpose(1, 2)\n",
        "        out = out.reshape(shape)\n",
        "        return out"
      ],
      "metadata": {
        "id": "B4uCv88DTEoa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Channel(nn.Module):\n",
        "    def __init__(self, snr, cplx=False):\n",
        "        super(Channel, self).__init__()\n",
        "        self.cplx = cplx\n",
        "        self.set_snr(snr)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        shape = inputs.shape\n",
        "        gnoise = torch.randn(shape) * self.noise_std\n",
        "        return inputs + gnoise.to(device)\n",
        "\n",
        "    def get_snr(self):\n",
        "        return self.snr\n",
        "\n",
        "    def set_snr(self, snr):\n",
        "        self.snr = snr\n",
        "        if self.cplx:\n",
        "            self.noise_std = np.sqrt(10**(-snr/10)) / np.sqrt(2)\n",
        "        else:\n",
        "            self.noise_std = np.sqrt(10**(-snr/10))\n"
      ],
      "metadata": {
        "id": "7DtTZXaKTo06"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_psnr(output, target, max_val=1.0):\n",
        "    mse = nn.functional.mse_loss(output, target)\n",
        "    psnr = 10 * torch.log10(max_val ** 2 / mse)\n",
        "    return psnr"
      ],
      "metadata": {
        "id": "NblCxJIH6Avu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PSNR_plotter(x_axis, model, channel, test_loader, stages_count=1, goal=None):\n",
        "    sc = stages_count\n",
        "    PSNRs = np.zeros((sc, len(x_axis)))\n",
        "    pre_snr = channel.get_snr()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, snr in enumerate(x_axis):\n",
        "            channel.set_snr(snr)\n",
        "            batch_psnrs = [[] for _ in range(sc)]\n",
        "\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                preds = model(data)\n",
        "\n",
        "                for j in range(sc):\n",
        "                    psnr = calculate_psnr(preds[j], target)\n",
        "                    batch_psnrs[j].append(psnr.item())\n",
        "\n",
        "            # Average the PSNR values over the test set for each stage\n",
        "            for j in range(sc):\n",
        "                PSNRs[j, i] = np.mean(batch_psnrs[j])\n",
        "\n",
        "    channel.set_snr(pre_snr)\n",
        "\n",
        "    # Plotting\n",
        "    for i in range(sc):\n",
        "        plt.plot(x_axis, PSNRs[i], label='Stage_' + str(i+1))\n",
        "    if goal is not None:\n",
        "        plt.plot(x_axis, goal, label='Goal')\n",
        "\n",
        "    plt.xlabel('SNR')\n",
        "    plt.ylabel('PSNR')\n",
        "    plt.title('PSNR vs SNR for Different Stages')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "C-lbjexTTuIL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PSNR_metric(nn.Module):\n",
        "    def __init__(self, name=\"PSNR\"):\n",
        "        super(PSNR_metric, self).__init__()\n",
        "        self.name = name\n",
        "        self.PSNR_additive = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
        "        self.counter = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        mse = torch.mean((y_true - y_pred) ** 2)\n",
        "        psnr = 10 * torch.log10(1.0 / mse)\n",
        "        self.PSNR_additive += psnr\n",
        "        self.counter += 1\n",
        "\n",
        "    def result(self):\n",
        "        return self.PSNR_additive / self.counter if self.counter != 0 else torch.tensor(0.0)\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.PSNR_additive = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
        "        self.counter = nn.Parameter(torch.tensor(0.0), requires_grad=False)"
      ],
      "metadata": {
        "id": "01g60gacTxBC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lr_scheduler(epoch):\n",
        "  if epoch == 0:\n",
        "    print(\"\\nlearning_rate: 0.001\")\n",
        "  elif epoch == 20:\n",
        "    print(\"\\nlearning_rate: 0.0005\")\n",
        "  elif epoch == 30:\n",
        "    print(\"\\nlearning_rate: 0.0001\")\n",
        "\n",
        "  if epoch < 20:\n",
        "    return 0.001\n",
        "  elif epoch < 30:\n",
        "    return 0.0005\n",
        "  else:\n",
        "    return 0.0001"
      ],
      "metadata": {
        "id": "J7zh81q_T3dU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FuncCaller:\n",
        "    def __init__(self, period, function, *args, **kwargs):\n",
        "        self.period = period\n",
        "        self.fn = function\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % self.period == 0:\n",
        "            self.fn(*self.args, **self.kwargs)\n"
      ],
      "metadata": {
        "id": "EPBrYk8vT6cf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EpochDotter:\n",
        "    def __init__(self, nl_period, dot_period=1):\n",
        "        self.nl_period = nl_period\n",
        "        self.dot_period = dot_period\n",
        "        self.tic = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % self.dot_period == 0:\n",
        "            print('.', end='')\n",
        "\n",
        "        if epoch % self.nl_period == 0:\n",
        "            toc = time.time()\n",
        "            print(\" {} epochs\".format(epoch), end='')\n",
        "            if self.tic is not None:\n",
        "                print(\" - {0:.2f}s/epoch\".format((toc - self.tic)/self.nl_period), end='')\n",
        "            if logs is not None:\n",
        "                for key, value in logs.items():\n",
        "                    if \"val\" in key:\n",
        "                        print(\" - {}: {:.4f}\".format(key, value), end='')\n",
        "            print(\"\")\n",
        "            self.tic = time.time()"
      ],
      "metadata": {
        "id": "g9XOX2OgT-ZU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install git+https://github.com/modestyachts/ImageNetV2_pytorch"
      ],
      "metadata": {
        "id": "meG3nVUDA9yn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from imagenetv2_pytorch import ImageNetV2Dataset\n",
        "\n",
        "# Load the ImageNetV2 dataset\n",
        "#dataset = ImageNetV2Dataset(\"matched-frequency\")\n",
        "\n",
        "# Extract the first N images\n",
        "#N = 50  # Number of images you want to use\n",
        "#pil_images = [dataset[i][0] for i in range(N)]  # dataset[i][0] gives the PIL image"
      ],
      "metadata": {
        "id": "Amyg1IBSuicW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImagePatchesDataset(Dataset):\n",
        "    def __init__(self, images, patch_size, train_count, test_count):\n",
        "        self.images = images\n",
        "        self.patch_size = patch_size\n",
        "        self.train_count = train_count\n",
        "        self.test_count = test_count\n",
        "        self.patches = self._preprocess()\n",
        "\n",
        "    def _preprocess(self):\n",
        "        patches = []\n",
        "        l = 0\n",
        "        for img in self.images:\n",
        "            # Assuming img is a PIL Image, convert to NumPy array\n",
        "            img_np = np.array(img)\n",
        "            shape = img_np.shape\n",
        "            tile_dim0 = shape[0] // self.patch_size\n",
        "            tile_dim1 = shape[1] // self.patch_size\n",
        "            img_np = img_np[:tile_dim0 * self.patch_size, :tile_dim1 * self.patch_size]\n",
        "            img_np = img_np.reshape(tile_dim0, self.patch_size, tile_dim1, self.patch_size, shape[-1])\n",
        "            img_np = img_np.transpose(0, 2, 1, 3, 4)\n",
        "            img_np = img_np.reshape(tile_dim0 * tile_dim1, self.patch_size, self.patch_size, shape[-1])\n",
        "            patches.append(img_np)\n",
        "            l += len(img_np)\n",
        "            if l > (self.train_count + self.test_count):\n",
        "                break\n",
        "        return np.vstack(patches)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        patch = self.patches[idx]\n",
        "        patch = torch.tensor(patch).float() / 255.0\n",
        "        patch = patch.permute(2, 0, 1)  # Change to (C, H, W) format\n",
        "        return patch, patch  # Returning the same patch as input and target"
      ],
      "metadata": {
        "id": "Oq8eDNTfUEVc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir, ps, train_count, test_count):\n",
        "\n",
        "    # Transformaciones para el conjunto de datos\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),  # Convierte las imágenes a tensores de PyTorch\n",
        "    ])\n",
        "\n",
        "    # Cargar el conjunto de datos ImageNet-A\n",
        "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "    # DataLoader para PyTorch\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Proceso y división del conjunto de datos en parches\n",
        "    trainX, testX = [], []\n",
        "    total_patches = 0\n",
        "    for img, label in data_loader:\n",
        "        img = img.squeeze(0)  # Eliminar la dimensión del batch\n",
        "\n",
        "        # Proceso en parches\n",
        "        shape = img.shape\n",
        "        tile_dim0 = shape[1] // ps\n",
        "        tile_dim1 = shape[2] // ps\n",
        "        patches = img[:, :tile_dim0 * ps, :tile_dim1 * ps]\n",
        "        patches = patches.unfold(1, ps, ps).unfold(2, ps, ps)\n",
        "        patches = patches.contiguous().view(3, -1, ps, ps).permute(1, 0, 2, 3)\n",
        "\n",
        "        # Añadir parches a la lista\n",
        "        trainX.extend(patches)\n",
        "        total_patches += len(patches)\n",
        "        if total_patches > (train_count + test_count):\n",
        "            break\n",
        "\n",
        "    # Convertir la lista a tensor y dividir en entrenamiento y prueba\n",
        "    trainX = torch.stack(trainX)\n",
        "    trainX = trainX[:train_count + test_count]\n",
        "    trainX, testX = trainX[:train_count], trainX[train_count:]\n",
        "\n",
        "    # Normalizar los datos\n",
        "    trainX = trainX.float() / 255.0\n",
        "    testX = testX.float() / 255.0\n",
        "\n",
        "    return trainX, testX\n"
      ],
      "metadata": {
        "id": "BUxV6xl0L52f"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, out_chs):\n",
        "        super(Encoder, self).__init__()\n",
        "        # Definir las capas del encoder\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2)  # padding ajustado para 'same' efecto\n",
        "        self.prelu1 = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
        "        self.prelu2 = nn.PReLU()\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.prelu3 = nn.PReLU()\n",
        "        self.conv4 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.prelu4 = nn.PReLU()\n",
        "        self.conv5 = nn.Conv2d(32, out_chs, kernel_size=5, stride=1, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.prelu1(self.conv1(x))\n",
        "        x = self.prelu2(self.conv2(x))\n",
        "        x = self.prelu3(self.conv3(x))\n",
        "        x = self.prelu4(self.conv4(x))\n",
        "        x = self.conv5(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2ChCbirNUGJ8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_shape, img_chs=3):\n",
        "        super(Decoder, self).__init__()\n",
        "        # Asumiendo que input_shape es un triple (C, H, W)\n",
        "        self.conv1 = nn.ConvTranspose2d(input_shape[0], 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.prelu1 = nn.PReLU()\n",
        "        self.conv2 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.prelu2 = nn.PReLU()\n",
        "        self.conv3 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.prelu3 = nn.PReLU()\n",
        "        self.conv4 = nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.prelu4 = nn.PReLU()\n",
        "        self.conv5 = nn.ConvTranspose2d(16, img_chs, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.prelu1(self.conv1(x))\n",
        "        x = self.prelu2(self.conv2(x))\n",
        "        x = self.prelu3(self.conv3(x))\n",
        "        x = self.prelu4(self.conv4(x))\n",
        "        x = torch.sigmoid(self.conv5(x))  # Activación Sigmoid en la última capa\n",
        "        return x"
      ],
      "metadata": {
        "id": "dlaIOOs0UTiN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepJSCC(nn.Module):\n",
        "    def __init__(self, enc_chs, stages_count, SNR):\n",
        "        super(DeepJSCC, self).__init__()\n",
        "        self.encoder = create_encoder(enc_chs)\n",
        "        self.powernorm = PowerNormParts(stages_count, cplx=True)\n",
        "        self.channel = Channel(SNR, cplx=True)\n",
        "        self.decoders = nn.ModuleList([create_decoder(dec_chs * (i + 1)) for i in range(stages_count)])\n",
        "        self.loss_func = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_out = self.encoder(x)\n",
        "        power_out = self.powernorm(encoder_out)\n",
        "        channel_out = self.channel(power_out)\n",
        "\n",
        "        outputs = []\n",
        "        for i, decoder in enumerate(self.decoders):\n",
        "            decoder_input = channel_out[:, :dec_chs*(i+1), :, :]\n",
        "            decoder_output = decoder(decoder_input)\n",
        "            outputs.append(decoder_output)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def calculate_loss(self, target, outputs):\n",
        "      losses = []\n",
        "      for output in outputs:\n",
        "          # Ensure output and target have the same shape\n",
        "          if output.shape == target.shape:\n",
        "              loss = self.loss_func(output, target)\n",
        "              losses.append(loss)\n",
        "          else:\n",
        "              print(f\"Output shape {output.shape} does not match target shape {target.shape}\")\n",
        "      return sum(losses)"
      ],
      "metadata": {
        "id": "sKoGd8FOUgKf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, enc_chs, dec_chs, stages_count, SNR, img_chs=3):\n",
        "        super(Model, self).__init__()\n",
        "        # Crear el encoder\n",
        "        self.encoder = Encoder(out_chs=enc_chs)\n",
        "        # Crear el normalizador de potencia\n",
        "        self.powernorm = PowerNormParts(parts_count=stages_count, cplx=True)\n",
        "        # Crear el canal\n",
        "        self.channel = Channel(snr=SNR, cplx=True)\n",
        "        # Crear los decodificadores\n",
        "        self.decoders = nn.ModuleList()\n",
        "        for i in range(stages_count):\n",
        "            self.decoders.append(Decoder(input_shape=(dec_chs*(i+1), None, None), img_chs=img_chs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoder_out = self.encoder(x)\n",
        "        power_out = self.powernorm(encoder_out)\n",
        "        channel_out = self.channel(power_out)\n",
        "        outputs = []\n",
        "        for i, decoder in enumerate(self.decoders):\n",
        "            # Seleccionar las características relevantes para cada decodificador\n",
        "            decoder_input = channel_out[:, :dec_chs*(i+1), :, :]\n",
        "            outputs.append(decoder(decoder_input))\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "c7h5rEoQQXzi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Model(enc_chs, dec_chs, stages_count, SNR).to(device)\n",
        "\n",
        "trainX, testX = load_data(data_dir, patch_size, train_count, test_count)\n",
        "trainX = trainX.to(device)\n",
        "testX = testX.to(device)\n",
        "train_loader = DataLoader(trainX, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(testX, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: lr_scheduler(epoch))\n",
        "psnr_metrics = [PSNR_metric() for _ in range(len(model.decoders))]  # One PSNR_metric instance for each decoder"
      ],
      "metadata": {
        "id": "UcVu5x_bAaVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2985f9-5f52-44ca-fde3-ebca43255307"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "learning_rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "known_SNRs  = [1, 4, 7, 13, 19]\n",
        "test_SNRs   = [1, 4, 7, 10, 13, 16, 19, 22, 25]\n",
        "known_goals = [[24.636, 25.964, 26.618, 26.945, 27.109, 27.182, 27.236, 27.255, 27.273],\n",
        "              [23.836, 26.655, 28.091, 28.909, 29.309, 29.527, 29.636, 29.673, 29.709],\n",
        "              [21.836, 25.945, 28.545, 30.091, 31.055, 31.618, 31.945, 32.091, 32.182],\n",
        "              [21.036, 23.836, 26.455, 28.854, 30.836, 32.345, 33.382, 34.036, 34.382],\n",
        "              [20.291, 23.127, 25.891, 28.473, 30.745, 32.655, 34.073, 35.036, 35.600]]\n",
        "\n",
        "idx = np.where(np.array(known_SNRs) == SNR)[0]\n",
        "if idx.size == 0:\n",
        "  goal = None\n",
        "else:\n",
        "  idx = idx[0]\n",
        "  goal = known_goals[idx]\n",
        "\n",
        "goal = None   # we don't want to use the result of main paper here"
      ],
      "metadata": {
        "id": "cNl-eslwAb_6"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the EpochDotter\n",
        "epoch_dotter = EpochDotter(nl_period=10, dot_period=1)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        outputs = model(data)  # Forward pass, outputs is a list of tensors\n",
        "\n",
        "        # Calculate loss using the custom method\n",
        "        loss = model.calculate_loss(target, outputs)\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    scheduler.step()  # Update learning rate\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        validation_psnrs = []\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "\n",
        "            for i, output in enumerate(outputs):\n",
        "                psnr_metrics[i].update_state(target, output)\n",
        "\n",
        "        # Print PSNRs and reset states\n",
        "        for i, metric in enumerate(psnr_metrics):\n",
        "            avg_psnr = metric.result().item()\n",
        "            validation_psnrs.append(avg_psnr)\n",
        "            metric.reset_states()\n",
        "\n",
        "    # Print epoch information using EpochDotter\n",
        "    logs = {'val_loss': total_loss / len(train_loader), 'val_psnr': np.mean(validation_psnrs)}\n",
        "    epoch_dotter.on_epoch_end(epoch, logs)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        PSNR_plotter(test_SNRs, model, model.channel, test_loader, len(model.decoders), goal)\n",
        "\n",
        "# Save the entire model\n",
        "torch.save(model, 'entire_model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "hAIg2JiVAdnf",
        "outputId": "a06b1163-738e-4c24-ae04-57157b02d448"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-210e6ca0c3da>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zero the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert testX to a PyTorch tensor\n",
        "testX_tensor = torch.tensor(test_dataset, dtype=torch.float32)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Randomly select a subset of images from the test set\n",
        "idxs = np.random.randint(0, len(testX_tensor), 10)\n",
        "imgs = testX_tensor[idxs]\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():  # No gradients needed for evaluation\n",
        "    preds = model(imgs)\n",
        "\n",
        "# Plot the original images and predictions\n",
        "fig = plt.figure(figsize=(2.5 * (stages_count + 1), 2.5 * len(imgs)))\n",
        "for i in range(len(imgs)):\n",
        "    for j in range(stages_count):\n",
        "        # Convert the prediction back to a numpy array for plotting\n",
        "        pred = preds[j][i].cpu().numpy()\n",
        "        fig.add_subplot(len(imgs), stages_count + 1, i * (stages_count + 1) + j + 1)\n",
        "        plt.imshow(pred)\n",
        "        plt.axis('off')  # Hide the axis\n",
        "\n",
        "    # Plot the original image\n",
        "    fig.add_subplot(len(imgs), stages_count + 1, (i + 1) * (stages_count + 1))\n",
        "    plt.imshow(imgs[i].cpu().numpy())\n",
        "    plt.axis('off')  # Hide the axis\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ZsdN05aAl8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKIVIaisBEKL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}