{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "# Hyperparameters\n",
    "ps = 64  # Pixel size\n",
    "enc_chs = 5 * 4 * 2  # Encoder channels, calculated as a product of factors\n",
    "stages_count = 5  # Number of stages in the model\n",
    "dec_chs = enc_chs // stages_count  # Decoder channels, derived from encoder channels\n",
    "SNR = 13  # Signal-to-Noise Ratio\n",
    "\n",
    "# Training parameters\n",
    "epochs = 500  # Total number of training epochs\n",
    "batch_size = int(32 * (32 / ps) ** 2)  # Calculated batch size based on pixel size\n",
    "loss_func = nn.MSELoss()  # Loss function for the model, using Mean Squared Error\n",
    "\n",
    "# Data directory and channel name\n",
    "data_dir = \"data/raw/imagenet-a/\"  # Directory for the ImageNet-A dataset\n",
    "JSSC_channel_name = \"Channel\"  # Name of the channel for JSSC\n",
    "\n",
    "# Dataset size configuration\n",
    "train_count = int(50000 * (32 / ps) ** 2)  # Calculated number of training samples\n",
    "test_count = int(10000 * (32 / ps) ** 2)  # Calculated number of test samples\n",
    "\n",
    "# Device configuration for PyTorch\n",
    "global DEVICE  # Declaring DEVICE as a global variable\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Using GPU if available\n",
    "print(f\"DEVICE: {DEVICE}\")  # Printing the device information\n",
    "psnr = PeakSignalNoiseRatio().to(DEVICE)  # Initializing PSNR metric and moving it to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerNormParts(nn.Module):\n",
    "    def __init__(self, parts_count, cplx=False, part_last_dim=True):\n",
    "        \"\"\"\n",
    "        Initialize the PowerNormParts module.\n",
    "        :param parts_count: Number of parts to divide the input into.\n",
    "        :param cplx: Boolean indicating if complex numbers are used.\n",
    "        :param part_last_dim: Boolean indicating if the last dimension is used for parts.\n",
    "        \"\"\"\n",
    "        super(PowerNormParts, self).__init__()\n",
    "        self.parts_count = parts_count\n",
    "        self.cplx = cplx\n",
    "        self.part_last_dim = part_last_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the PowerNormParts module.\n",
    "        :param inputs: Input tensor to be processed.\n",
    "        :return: Normalized output tensor.\n",
    "        \"\"\"\n",
    "        # Reshaping and transposing inputs if necessary\n",
    "        shape = inputs.shape\n",
    "        if self.part_last_dim:\n",
    "            inputs = inputs.reshape(shape[0], -1, shape[-1])\n",
    "            inputs = inputs.transpose(1, 2)\n",
    "\n",
    "        # Processing inputs\n",
    "        flatp = inputs.reshape(shape[0], self.parts_count, -1)\n",
    "        if self.cplx:\n",
    "            dsize = flatp.shape[2] // 2\n",
    "        else:\n",
    "            dsize = flatp.shape[2]\n",
    "        dsize_f = float(dsize)\n",
    "\n",
    "        # Normalizing the inputs\n",
    "        norm = torch.norm(flatp, dim=2, keepdim=True)\n",
    "        out = torch.sqrt(torch.tensor(dsize_f)) * flatp / norm\n",
    "        if self.part_last_dim:\n",
    "            out = out.reshape(shape[0], shape[-1], -1)\n",
    "            out = out.transpose(1, 2)\n",
    "        out = out.reshape(shape)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel(nn.Module):\n",
    "    def __init__(self, snr, cplx=False):\n",
    "        \"\"\"\n",
    "        Initialize the Channel module.\n",
    "        :param snr: Signal-to-Noise Ratio for the channel.\n",
    "        :param cplx: Boolean indicating if complex numbers are used.\n",
    "        \"\"\"\n",
    "        super(Channel, self).__init__()\n",
    "        self.cplx = cplx  # Complex number flag\n",
    "        self.set_snr(snr)  # Setting the SNR\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the Channel module, simulating noise addition.\n",
    "        :param inputs: Input tensor to be processed.\n",
    "        :return: Input tensor with added Gaussian noise.\n",
    "        \"\"\"\n",
    "        shape = inputs.shape\n",
    "        gnoise = torch.randn(shape) * self.noise_std  # Generating Gaussian noise\n",
    "        device = inputs.device  # Getting the device of the inputs\n",
    "        return inputs + gnoise.to(device)  # Adding noise to the inputs\n",
    "\n",
    "    def get_snr(self):\n",
    "        \"\"\" Return the current SNR of the channel. \"\"\"\n",
    "        return self.snr\n",
    "\n",
    "    def set_snr(self, snr):\n",
    "        \"\"\"\n",
    "        Set the SNR of the channel and calculate the corresponding noise standard deviation.\n",
    "        :param snr: New Signal-to-Noise Ratio value.\n",
    "        \"\"\"\n",
    "        self.snr = snr\n",
    "        if self.cplx:\n",
    "            self.noise_std = np.sqrt(10 ** (-snr / 10)) / np.sqrt(2)\n",
    "        else:\n",
    "            self.noise_std = np.sqrt(10 ** (-snr / 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR_plotter(x_axis, model, testloader, epoch, stages_count=1, goal=None):\n",
    "    \"\"\"\n",
    "    Plot the PSNR values for different SNR levels.\n",
    "    :param x_axis: SNR values to evaluate the model on.\n",
    "    :param model: The model to evaluate.\n",
    "    :param testloader: Test loader.\n",
    "    :param epoch: Current training epoch.\n",
    "    :param stages_count: Number of stages in the model.\n",
    "    :param goal: Optional goal line to plot.\n",
    "    \"\"\"\n",
    "    spsnr = PeakSignalNoiseRatio()\n",
    "    sc = stages_count\n",
    "    PSNRs = np.zeros((sc, len(x_axis)))\n",
    "    pre_snr = model.channel.get_snr()  # Storing the initial SNR\n",
    "    psnr_val = []\n",
    "    for i, snr in enumerate(x_axis):\n",
    "        model.channel.set_snr(snr)\n",
    "        psnr_val.append(evaluate_psnr(model, testloader, psnr, device='cpu'))\n",
    "\n",
    "    model.channel.set_snr(pre_snr)  # Resetting the SNR to its initial value\n",
    "    PSNRs = np.asarray(psnr_val).squeeze().transpose()\n",
    "    if sc == 1:\n",
    "        plt.plot(x_axis, PSNRs[0], label='Model')\n",
    "    else:\n",
    "        for i in range(sc):\n",
    "            plt.plot(x_axis, PSNRs[i], label=f'Stage_{i+1}')\n",
    "    if goal is not None:\n",
    "        plt.plot(x_axis, goal, label='Goal')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(f\"models/test_1/images/epoch_{epoch}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSNR_metric(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the PSNR_metric module.\n",
    "        This module accumulates PSNR values over multiple batches and computes their average.\n",
    "        \"\"\"\n",
    "        super(PSNR_metric, self).__init__()\n",
    "        self.PSNR_additive = torch.tensor(0.0)  # Sum of PSNR values\n",
    "        self.counter = torch.tensor(0.0)  # Counter for the number of batches\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Forward pass to accumulate PSNR value.\n",
    "        :param y_true: Ground truth tensor.\n",
    "        :param y_pred: Predicted tensor.\n",
    "        :return: Current average PSNR over all batches.\n",
    "        \"\"\"\n",
    "        self.PSNR_additive += psnr(y_true, y_pred).mean()  # Accumulating PSNR\n",
    "        self.counter += 1  # Incrementing counter\n",
    "        return self.PSNR_additive / self.counter  # Returning average PSNR\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\" Reset the PSNR additive and counter to zero. \"\"\"\n",
    "        self.PSNR_additive = torch.tensor(0.0)\n",
    "        self.counter = torch.tensor(0.0)\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        Compute the average PSNR.\n",
    "        :return: Average PSNR if counter is not zero; otherwise, returns zero.\n",
    "        \"\"\"\n",
    "        return self.PSNR_additive / self.counter if self.counter != 0 else torch.tensor(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "    \"\"\"\n",
    "    Adjusts the learning rate based on the epoch number.\n",
    "    :param epoch: Current epoch number.\n",
    "    :param lr: Current learning rate.\n",
    "    :return: Adjusted learning rate.\n",
    "    \"\"\"\n",
    "    if epoch == 0:\n",
    "        print(\"\\nlearning_rate: 0.001\")\n",
    "    elif epoch == 20:\n",
    "        print(\"\\nlearning_rate: 0.0005\")\n",
    "    elif epoch == 30:\n",
    "        print(\"\\nlearning_rate: 0.0001\")\n",
    "\n",
    "    # Adjusting learning rate based on epoch\n",
    "    if epoch < 20:\n",
    "        return 0.001\n",
    "    elif epoch < 30:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, ps, train_count, test_count):\n",
    "    \"\"\"\n",
    "    Load and preprocess data from the specified directory.\n",
    "    :param data_dir: Directory of the dataset.\n",
    "    :param ps: Size of each image patch.\n",
    "    :param train_count: Number of training samples to generate.\n",
    "    :param test_count: Number of test samples to generate.\n",
    "    :return: Tuple of training and testing datasets.\n",
    "    \"\"\"\n",
    "    # Image transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    ])\n",
    "\n",
    "    # Load the ImageNet-A dataset\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "    # DataLoader for PyTorch\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Process and split the dataset into patches\n",
    "    trainX, testX = [], []\n",
    "    total_patches = 0\n",
    "    for img, label in data_loader:\n",
    "        img = img.squeeze(0)  # Remove the batch dimension\n",
    "\n",
    "        # Patch processing\n",
    "        shape = img.shape\n",
    "        tile_dim0 = shape[1] // ps\n",
    "        tile_dim1 = shape[2] // ps\n",
    "        patches = img[:, :tile_dim0 * ps, :tile_dim1 * ps]\n",
    "        patches = patches.unfold(1, ps, ps).unfold(2, ps, ps)\n",
    "        patches = patches.contiguous().view(3, -1, ps, ps).permute(1, 0, 2, 3)\n",
    "\n",
    "        # Add patches to the list\n",
    "        trainX.extend(patches)\n",
    "        total_patches += len(patches)\n",
    "        if total_patches > (train_count + test_count):\n",
    "            break\n",
    "\n",
    "    # Convert list to tensor and split into train and test\n",
    "    trainX = torch.stack(trainX)\n",
    "    train_count = int(0.7 * len(trainX))\n",
    "    test_count = int(len(trainX) - train_count)\n",
    "    trainX = trainX[:train_count + test_count]\n",
    "    trainX, testX = trainX[:train_count], trainX[train_count:]\n",
    "\n",
    "    # Normalize the data\n",
    "    trainX = trainX.float() / 255.0\n",
    "    testX = testX.float() / 255.0\n",
    "\n",
    "    return trainX, testX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_chs):\n",
    "        \"\"\"\n",
    "        Initialize the Encoder module.\n",
    "        :param out_chs: Number of output channels.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        # Define encoder layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.prelu4 = nn.PReLU()\n",
    "        self.conv5 = nn.Conv2d(32, out_chs, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Encoder.\n",
    "        :param x: Input tensor.\n",
    "        :return: Encoded output tensor.\n",
    "        \"\"\"\n",
    "        x = self.prelu1(self.conv1(x))\n",
    "        x = self.prelu2(self.conv2(x))\n",
    "        x = self.prelu3(self.conv3(x))\n",
    "        x = self.prelu4(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_shape, img_chs=3):\n",
    "        \"\"\"\n",
    "        Initialize the Decoder module.\n",
    "        :param input_shape: Shape of the input tensor.\n",
    "        :param img_chs: Number of image channels.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        # Assuming input_shape is a tuple (C, H, W)\n",
    "        self.conv1 = nn.ConvTranspose2d(input_shape[0], 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.conv2 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.conv3 = nn.ConvTranspose2d(32, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.conv4 = nn.ConvTranspose2d(32, 16, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        self.prelu4 = nn.PReLU()\n",
    "        self.conv5 = nn.ConvTranspose2d(16, img_chs, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Decoder.\n",
    "        :param x: Input tensor.\n",
    "        :return: Decoded output tensor.\n",
    "        \"\"\"\n",
    "        x = self.prelu1(self.conv1(x))\n",
    "        x = self.prelu2(self.conv2(x))\n",
    "        x = self.prelu3(self.conv3(x))\n",
    "        x = self.prelu4(self.conv4(x))\n",
    "        x = torch.sigmoid(self.conv5(x))  # Sigmoid activation in the last layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, enc_chs, dec_chs, stages_count, SNR, img_chs=3):\n",
    "        \"\"\"\n",
    "        Initialize the Model.\n",
    "        :param enc_chs: Number of encoder channels.\n",
    "        :param dec_chs: Number of decoder channels.\n",
    "        :param stages_count: Number of stages in the model.\n",
    "        :param SNR: Signal-to-Noise Ratio.\n",
    "        :param img_chs: Number of image channels.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        # Create the encoder\n",
    "        self.encoder = Encoder(out_chs=enc_chs)\n",
    "        # Create the power normalizer\n",
    "        self.powernorm = PowerNormParts(parts_count=stages_count, cplx=True)\n",
    "        # Create the channel\n",
    "        self.channel = Channel(snr=SNR, cplx=True)\n",
    "        # Create the decoders\n",
    "        self.decoders = nn.ModuleList()\n",
    "        for i in range(stages_count):\n",
    "            self.decoders.append(Decoder(input_shape=(dec_chs * (i + 1), None, None), img_chs=img_chs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the Model.\n",
    "        :param x: Input tensor.\n",
    "        :return: List of outputs from each decoding stage.\n",
    "        \"\"\"\n",
    "        encoder_out = self.encoder(x)\n",
    "        power_out = self.powernorm(encoder_out)\n",
    "        channel_out = self.channel(power_out)\n",
    "        outputs = []\n",
    "        for i, decoder in enumerate(self.decoders):\n",
    "            # Select relevant features for each decoder\n",
    "            decoder_input = channel_out[:, :dec_chs * (i + 1), :, :]\n",
    "            outputs.append(decoder(decoder_input))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_SNRs  = [1, 4, 7, 13, 19]\n",
    "test_SNRs   = [1, 4, 7, 10, 13, 16, 19, 22, 25]\n",
    "known_goals = [[24.636, 25.964, 26.618, 26.945, 27.109, 27.182, 27.236, 27.255, 27.273],\n",
    "              [23.836, 26.655, 28.091, 28.909, 29.309, 29.527, 29.636, 29.673, 29.709],\n",
    "              [21.836, 25.945, 28.545, 30.091, 31.055, 31.618, 31.945, 32.091, 32.182],\n",
    "              [21.036, 23.836, 26.455, 28.854, 30.836, 32.345, 33.382, 34.036, 34.382],\n",
    "              [20.291, 23.127, 25.891, 28.473, 30.745, 32.655, 34.073, 35.036, 35.600]]\n",
    "# Initialize the model and move it to the appropriate device\n",
    "model = Model(enc_chs, dec_chs, stages_count, SNR).to(DEVICE)\n",
    "\n",
    "# Load and preprocess data\n",
    "trainX, testX = load_data(data_dir, ps, train_count, test_count)\n",
    "trainX = trainX.to(DEVICE)\n",
    "testX = testX.to(DEVICE)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = DataLoader(trainX, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testX, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Setup the optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: lr_scheduler(epoch, 0.001))\n",
    "\n",
    "# Initialize PSNR metric\n",
    "psnr_metric = PSNR_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_func, epoch):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    :param model: The neural network model.\n",
    "    :param train_loader: DataLoader for training data.\n",
    "    :param optimizer: Optimizer for model parameters.\n",
    "    :param loss_func: Loss function.\n",
    "    :param epoch: Current epoch number.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        inputs = data.to(DEVICE)\n",
    "        optimizer.zero_grad()  # Zero out any existing gradients\n",
    "        outputs = model(inputs)  # Get model outputs\n",
    "        loss = loss_func(torch.stack(outputs), torch.stack([inputs] * stages_count))  # Calculate loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "        total_loss += loss.item()\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psnr(outputs, input, psnr):\n",
    "    \"\"\"\n",
    "    Calculate PSNR for each output channel.\n",
    "    :param outputs: List of output tensors from the model.\n",
    "    :param input: Input tensor.\n",
    "    :param psnr: PSNR calculation function.\n",
    "    :return: Array of PSNR values for each channel.\n",
    "    \"\"\"\n",
    "    psnr_values = [psnr(input, output).cpu() for output in outputs]\n",
    "    return np.array(psnr_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_psnr(model, test_loader, psnr, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data and calculate average PSNR.\n",
    "    :param model: The neural network model.\n",
    "    :param test_loader: DataLoader for testing data.\n",
    "    :param psnr: PSNR calculation function.\n",
    "    :param device: Device to run the evaluation on.\n",
    "    :return: Average PSNR value.\n",
    "    \"\"\"\n",
    "    psnr_val = np.zeros([1, 5])\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():  # No gradient calculation for evaluation\n",
    "        count = 0\n",
    "        for data in test_loader:\n",
    "            inputs = data.to(device)\n",
    "            outputs = model(inputs)\n",
    "            psnr_val += get_psnr(outputs, inputs, psnr)\n",
    "            count += 1\n",
    "        avg_psnr = psnr_val / count\n",
    "    model.to(DEVICE)  # Move model back to the original device\n",
    "    return avg_psnr\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    min_psnr = 0.0\n",
    "    train(model, train_loader, optimizer, loss_func, epoch)\n",
    "    scheduler.step()  # Update the learning rate\n",
    "\n",
    "    # Save the model and evaluate PSNR at specified intervals\n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(model.state_dict(), f\"models/test_1/models/{JSSC_channel_name}_model_{epoch}.pth\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        avg_psnr = evaluate_psnr(model, test_loader, psnr, DEVICE).squeeze()\n",
    "        if avg_psnr.mean() > min_psnr:\n",
    "            min_psnr = avg_psnr.mean()\n",
    "            torch.save(model.state_dict(), f\"models/test_1/models/{JSSC_channel_name}_model_best.pth\")\n",
    "\n",
    "        PSNR_plotter(test_SNRs, model, test_loader, epoch, stages_count)\n",
    "        print(f\"Epoch {epoch}, PSNR channel_1: {avg_psnr[0]}, PSNR channel_2: {avg_psnr[1]}, PSNR channel_3: {avg_psnr[2]}, PSNR channel_4: {avg_psnr[3]}, PSNR channel_5: {avg_psnr[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    total_psnr = 0.0\n",
    "    count = 0\n",
    "    for data in test_loader:\n",
    "        inputs = data.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        total_psnr += psnr(inputs, outputs[-1]).mean().item()  # Calculate PSNR for the last output\n",
    "        count += 1\n",
    "    avg_psnr = total_psnr / count\n",
    "    PSNR_plotter(test_SNRs, model, testX, epochs, stages_count)  # Plot PSNR for the final epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
