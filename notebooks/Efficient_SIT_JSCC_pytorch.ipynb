{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class PowerNormParts(nn.Module):\n",
    "    def __init__(self, parts_count, cplx=False, part_last_dim=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pc = parts_count\n",
    "        self.cplx = cplx\n",
    "        self.part_last_dim = part_last_dim  # if False, partitions the second dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        shape = inputs.shape\n",
    "        if self.part_last_dim:\n",
    "            inputs = inputs.view(shape[0], -1, shape[-1]).permute(0, 2, 1)\n",
    "\n",
    "        flatp = inputs.view(shape[0], self.pc, -1)\n",
    "        if self.cplx:\n",
    "            dsize = flatp.shape[2] // 2\n",
    "        else:\n",
    "            dsize = flatp.shape[2]\n",
    "        dsize_f = torch.cast(dsize, dtype=torch.float32)\n",
    "\n",
    "        norm = torch.norm(flatp, dim=2).real()\n",
    "        norm = norm.unsqueeze(dim=-1)\n",
    "\n",
    "        out = torch.sqrt(dsize_f) * flatp / norm\n",
    "        if self.part_last_dim:\n",
    "            out = out.view(shape[0], shape[-1], -1).permute(0, 2, 1)\n",
    "        out = out.view(shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel(nn.Module):\n",
    "    def __init__(self, snr, cplx=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cplx = cplx\n",
    "        self.snr = snr\n",
    "        self.set_noise_std()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        shape = inputs.shape\n",
    "        gnoise = torch.randn(shape, mean=0, std=self.noise_std)\n",
    "        return inputs + gnoise\n",
    "\n",
    "    def get_snr(self):\n",
    "        return self.snr\n",
    "\n",
    "    def set_snr(self, snr):\n",
    "        self.snr = snr\n",
    "        self.set_noise_std()\n",
    "\n",
    "    def set_noise_std(self):\n",
    "        if self.cplx:\n",
    "            self.noise_std = np.sqrt(10**(-self.snr/10)) / np.sqrt(2)\n",
    "        else:\n",
    "            self.noise_std = np.sqrt(10**(-self.snr/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR_plotter(x_axis, model, channel, testX, stages_count=1, goal=None):\n",
    "    sc = stages_count\n",
    "    PSNRs = np.zeros((sc, len(x_axis)))\n",
    "    pre_snr = channel.get_snr()\n",
    "\n",
    "    for i, snr in enumerate(x_axis):\n",
    "        channel.set_snr(snr)\n",
    "        preds = model(testX)\n",
    "\n",
    "        for j in range(sc):\n",
    "            preds_stage = preds[j]\n",
    "            PSNRs[j, i] = torch.mean(torch.image.psnr(testX, preds_stage, max_val=1.0))\n",
    "\n",
    "    channel.set_snr(pre_snr)\n",
    "\n",
    "    if sc == 1:\n",
    "        plt.plot(x_axis, PSNRs[i], label='Model')\n",
    "    else:\n",
    "        for i in range(sc):\n",
    "            plt.plot(x_axis, PSNRs[i], label='Stage_' + str(i + 1))\n",
    "\n",
    "    if goal is not None:\n",
    "        plt.plot(x_axis, goal, label='Goal')\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Metric\n",
    "\n",
    "class PSNRMetric(Metric):\n",
    "    \"\"\"Computes the Peak Signal-to-Noise Ratio (PSNR) between two tensors.\n",
    "\n",
    "    Args:\n",
    "        name (str, optional): Name of the metric. Defaults to \"PSNR\".\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"PSNR\"):\n",
    "        super().__init__(name=name)\n",
    "        self.add_state(\"PSNR_additive\", default=torch.zeros(1), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"counter\", default=torch.zeros(1), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, y_true, y_pred):\n",
    "        \"\"\"Updates the metric with the given predictions and ground truth labels.\n",
    "\n",
    "        Args:\n",
    "            y_true (torch.Tensor): Ground truth labels.\n",
    "            y_pred (torch.Tensor): Predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        PSNR = torch.mean(torch.image.psnr(y_true, y_pred, max_val=1.0))\n",
    "        self.PSNR_additive += PSNR\n",
    "        self.counter += 1\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"Computes the metric value.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The PSNR value.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.PSNR_additive / self.counter\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the metric state to its initial values.\n",
    "        \"\"\"\n",
    "\n",
    "        self.PSNR_additive.zero_()\n",
    "        self.counter.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_scheduler(epoch, lr):\n",
    "  if epoch == 0:\n",
    "    print(\"\\nlearning_rate: 0.001\")\n",
    "  elif epoch == 20:\n",
    "    print(\"\\nlearning_rate: 0.0005\")\n",
    "  elif epoch == 30:\n",
    "    print(\"\\nlearning_rate: 0.0001\")\n",
    "\n",
    "  if epoch < 20:\n",
    "    return 0.001\n",
    "  elif epoch < 30:\n",
    "    return 0.0005\n",
    "  else:\n",
    "    return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "from typing import Any, Callable\n",
    "\n",
    "class FuncCaller(object):\n",
    "    def __init__(self, period: int, function: Callable, *args: Any, **kwargs: Any):\n",
    "        self.period = period\n",
    "        self.fn = function\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, epoch: int, train_loader: DataLoader, model: Any, optimizer: Optimizer, loss: Any, **kwargs: Any) -> None:\n",
    "        if epoch % self.period == 0:\n",
    "            self.fn(*self.args, **self.kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "from typing import Any, Callable\n",
    "\n",
    "class EpochDotter(object):\n",
    "    def __init__(self, nl_period: int, dot_period: int = 1):\n",
    "        self.nl_period = nl_period\n",
    "        self.dot_period = dot_period\n",
    "        self.tic = None\n",
    "\n",
    "    def __call__(self, epoch: int, train_loader: DataLoader, model: Any, optimizer: Optimizer, loss: Any, **kwargs: Any) -> None:\n",
    "        if epoch % self.dot_period == 0:\n",
    "            print('.', end='')\n",
    "\n",
    "        if epoch % self.nl_period == 0:\n",
    "            toc = time.time()\n",
    "            print(\" {} epochs\".format(epoch), end='')\n",
    "            if self.tic is not None:\n",
    "                print(\" - {0:.2f}s/epoch\".format((toc - self.tic) / self.nl_period), end='')\n",
    "            for key in list(kwargs.keys()):\n",
    "                print(\" - {}: {}\".format(key, kwargs[key]), end='')\n",
    "            print(\"\")\n",
    "            self.tic = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(out_chs, img_shape=(None, None, 3), name=None):\n",
    "    encoder = nn.Sequential(name=name)\n",
    "    encoder.add_module('input', nn.Conv2d(3, 16, kernel_size=5, stride=2, padding=2))\n",
    "    encoder.add_module('prelu1', nn.PReLU())\n",
    "    encoder.add_module('conv1', nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2))\n",
    "    encoder.add_module('prelu2', nn.PReLU())\n",
    "    encoder.add_module('conv2', nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2))\n",
    "    encoder.add_module('prelu3', nn.PReLU())\n",
    "    encoder.add_module('conv3', nn.Conv2d(32, out_chs, kernel_size=5, stride=1, padding=2))\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(input_shape, img_chs=3, name=None):\n",
    "    decoder = nn.Sequential(name=name)\n",
    "    decoder.add_module('input', nn.ConvTranspose2d(32, 32, kernel_size=5, stride=1, padding=2))\n",
    "    decoder.add_module('prelu1', nn.PReLU())\n",
    "    decoder.add_module('convtranspose1', nn.ConvTranspose2d(32, 32, kernel_size=5, stride=1, padding=2))\n",
    "    decoder.add_module('prelu2', nn.PReLU())\n",
    "    decoder.add_module('convtranspose2', nn.ConvTranspose2d(32, 16, kernel_size=5, stride=1, padding=2))\n",
    "    decoder.add_module('prelu3', nn.PReLU())\n",
    "    decoder.add_module('convtranspose3', nn.ConvTranspose2d(16, img_chs, kernel_size=5, stride=2, padding=2, output_padding=1))\n",
    "    decoder.add_module('sigmoid', nn.Sigmoid())\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = 64   # patch size (Height and Width)\n",
    "enc_chs = 5 * 4*2    # compression_ratio = 5 * 1/12\n",
    "stages_count = 5\n",
    "dec_chs = enc_chs // stages_count\n",
    "SNR = 13\n",
    "\n",
    "epochs = 500\n",
    "batch_size = int(32 * (32/ps)**2)\n",
    "loss_func = keras.losses.MeanSquaredError()\n",
    "\n",
    "drive_dir = '/content/drive/'\n",
    "JSCC_dir = os.path.join(drive_dir, 'MyDrive/Colab Stuff/Efficient_successive_img_tr/JSCC_2')\n",
    "JSCC_channel_name = 'Channel'   # to save the channel with this name, for further usage\n",
    "\n",
    "train_count = int(50000 * (32/ps)**2)   # number of patches in trainset\n",
    "test_count = int(10000 * (32/ps)**2)   # number of patches in testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_chs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7188\\1380287914.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_chs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Encoder\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpowernorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPowerNormParts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstages_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcplx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"PowerNorm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mchannel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChannel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSNR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcplx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJSCC_channel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enc_chs' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create layers\n",
    "encoder = create_encoder(enc_chs, img_shape=(None, None, 3), name=\"Encoder\")\n",
    "powernorm = PowerNormParts(stages_count, cplx=True, name=\"PowerNorm\")\n",
    "channel = Channel(SNR, cplx=True, name=JSCC_channel_name)\n",
    "decoders = []\n",
    "for i in range(stages_count):\n",
    "    decoders.append(create_decoder((None, None, dec_chs * (i + 1)), img_chs=3, name=\"Decoder_\" + str(i + 1)))\n",
    "\n",
    "# Construct the model\n",
    "model_input = torch.randn(1, 3, 224, 224)  # Sample input to initialize the model\n",
    "encoder_out = encoder(model_input)\n",
    "power_out = powernorm(encoder_out)\n",
    "channel_out = channel(power_out)\n",
    "outputs = []\n",
    "losses = []\n",
    "for i in range(stages_count):\n",
    "    outputs.append(decoders[i](channel_out[:, :, :, :dec_chs * (i + 1)]))\n",
    "    losses.append(loss_func(model_input, outputs[i]))\n",
    "\n",
    "raw_model = nn.Sequential(encoder, powernorm, channel, *decoders)\n",
    "model = nn.Sequential(encoder, powernorm, channel, *decoders)\n",
    "\n",
    "for loss in losses:\n",
    "    model.add_loss(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
